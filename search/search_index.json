{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Anton Latukha's place \u00b6 Better go have a tea, go outside and meditate, then work-out. If you are still here... Well. You can walk around here, look & stuff, until you go and decide to become for me the world again. (2019-06-25) I am seriously digging Computer sciences, mostly from the Haskell and Category theory side, and so also related mathematic theories. I am a solid beginner. I love philosophy, sometimes it makes things plesent and better, sometimes the contrary. Over time I want to go as deep as I can into mathematic philosophies. To observe it you can go to my open semantic notes: https://github.com/Anton-Latukha/haskell-notes I have a lot of personal documentation inside my noting system. Nix, NixOS, NixPkgs is also my passion. I was completely traditional DevOps before that. Sometimes I am using both worlds of knowledge. I am Nix contributor and a small maintainer of couple of packages, I like to take and earnestly keep my obligations. At the time I progress in Haskell and started contributing little-by-little into HNix (Haskell reimplementation of Nix) All written content on this site is provided under a Creative Commons ShareAlike license. All code is provided under a MIT license unless otherwise stated.","title":"Home"},{"location":"#welcome-to-anton-latukhas-place","text":"Better go have a tea, go outside and meditate, then work-out. If you are still here... Well. You can walk around here, look & stuff, until you go and decide to become for me the world again. (2019-06-25) I am seriously digging Computer sciences, mostly from the Haskell and Category theory side, and so also related mathematic theories. I am a solid beginner. I love philosophy, sometimes it makes things plesent and better, sometimes the contrary. Over time I want to go as deep as I can into mathematic philosophies. To observe it you can go to my open semantic notes: https://github.com/Anton-Latukha/haskell-notes I have a lot of personal documentation inside my noting system. Nix, NixOS, NixPkgs is also my passion. I was completely traditional DevOps before that. Sometimes I am using both worlds of knowledge. I am Nix contributor and a small maintainer of couple of packages, I like to take and earnestly keep my obligations. At the time I progress in Haskell and started contributing little-by-little into HNix (Haskell reimplementation of Nix) All written content on this site is provided under a Creative Commons ShareAlike license. All code is provided under a MIT license unless otherwise stated.","title":"Welcome to Anton Latukha's place"},{"location":"2017-04-12-SaltStack-Formulas-install/","text":"SaltStack formulas presetup/install/testing/usage \u00b6 Look through docs briefly \u00b6 Official Doc (not so great, but useful) Installation \u00b6 Prepare Salt formulas \u00b6 Fork what you want from salt formulas . Why? Because official documentation points to it, but also unconditionally requires . Create a branch in formulas \u00b6 Correspond to your environment ('base' in my setup): 1 2 3 4 git clone formula git cd formula git checkout -b 'base' git push origin 'base' Install Git Backend in Python \u00b6 Need to use deprecated Dulwich on Arch. preferred pygit2 is installed, but was not working on Arch. Officail notes: installing-dependencies . In Arch Linux: 1 yaourt -Syu python2-dulwich Or use PIP install: 1 pip install pygit2 1 pip install gitpython 1 pip install dulwich Enable Salt to use GIT backend \u00b6 1 2 3 4 5 /etc/salt/master --- fileserver_backend : - git - roots These list going to be searched through in listed order. More at: section on fileserver backends . Enable formula remote repos \u00b6 1 2 3 4 /etc/salt/master --- gitfs_remotes : - https://github.com/saltstack-formulas/docker-formula.git Reference information: You add that as remote repository of formulas. official doc This is basically works as literal remote fs. official doc Official documentation has an error \u00b6 Bug Be sure to put '.git' at the end of GIT URLs . Salt requires them to parse links with python backends. Formulas usage \u00b6 To use formulas: \u00b6 in sls file 1 2 3 * .sls --- - docker or 1 2 3 * .sls --- docker : to install formula using docker-formula. Look at GitHub documentation of formulas to see how to do install with it and other actions. Name of formula does not required to correspond to install command. Like here . To overload formula: \u00b6 You can extend formulas or use their source. To include formula source in sls (you can overload, like docker.sls) 1 2 3 4 docker.sls --- include : - docker Here docker-formula source included in docker.sls, and add your commands, formulas and so on. That is called overload. Testing \u00b6 Check if SaltStack formula works \u00b6 1 sudo salt 'host' state.show_sls docker To debug Master \u00b6 1 sudo salt-master -l debug If you get: [CRITICAL] No suitable gitfs provider module is installed. \u00b6 SaltStack can not find python git backend (pygit2, GitPython or Dulwich). So you need to figure-out this. Look at Docker state module \u00b6 https://docs.saltstack.com/en/latest/ref/states/all/salt.states.dockerng.html#module-salt.states.dockerng","title":"SaltStack formulas"},{"location":"2017-04-12-SaltStack-Formulas-install/#saltstack-formulas-presetupinstalltestingusage","text":"","title":"SaltStack formulas presetup/install/testing/usage"},{"location":"2017-04-12-SaltStack-Formulas-install/#look-through-docs-briefly","text":"Official Doc (not so great, but useful)","title":"Look through docs briefly"},{"location":"2017-04-12-SaltStack-Formulas-install/#installation","text":"","title":"Installation"},{"location":"2017-04-12-SaltStack-Formulas-install/#prepare-salt-formulas","text":"Fork what you want from salt formulas . Why? Because official documentation points to it, but also unconditionally requires .","title":"Prepare Salt formulas"},{"location":"2017-04-12-SaltStack-Formulas-install/#create-a-branch-in-formulas","text":"Correspond to your environment ('base' in my setup): 1 2 3 4 git clone formula git cd formula git checkout -b 'base' git push origin 'base'","title":"Create a branch in formulas"},{"location":"2017-04-12-SaltStack-Formulas-install/#install-git-backend-in-python","text":"Need to use deprecated Dulwich on Arch. preferred pygit2 is installed, but was not working on Arch. Officail notes: installing-dependencies . In Arch Linux: 1 yaourt -Syu python2-dulwich Or use PIP install: 1 pip install pygit2 1 pip install gitpython 1 pip install dulwich","title":"Install Git Backend in Python"},{"location":"2017-04-12-SaltStack-Formulas-install/#enable-salt-to-use-git-backend","text":"1 2 3 4 5 /etc/salt/master --- fileserver_backend : - git - roots These list going to be searched through in listed order. More at: section on fileserver backends .","title":"Enable Salt to use GIT backend"},{"location":"2017-04-12-SaltStack-Formulas-install/#enable-formula-remote-repos","text":"1 2 3 4 /etc/salt/master --- gitfs_remotes : - https://github.com/saltstack-formulas/docker-formula.git Reference information: You add that as remote repository of formulas. official doc This is basically works as literal remote fs. official doc","title":"Enable formula remote repos"},{"location":"2017-04-12-SaltStack-Formulas-install/#official-documentation-has-an-error","text":"Bug Be sure to put '.git' at the end of GIT URLs . Salt requires them to parse links with python backends.","title":"Official documentation has an error"},{"location":"2017-04-12-SaltStack-Formulas-install/#formulas-usage","text":"","title":"Formulas usage"},{"location":"2017-04-12-SaltStack-Formulas-install/#to-use-formulas","text":"in sls file 1 2 3 * .sls --- - docker or 1 2 3 * .sls --- docker : to install formula using docker-formula. Look at GitHub documentation of formulas to see how to do install with it and other actions. Name of formula does not required to correspond to install command. Like here .","title":"To use formulas:"},{"location":"2017-04-12-SaltStack-Formulas-install/#to-overload-formula","text":"You can extend formulas or use their source. To include formula source in sls (you can overload, like docker.sls) 1 2 3 4 docker.sls --- include : - docker Here docker-formula source included in docker.sls, and add your commands, formulas and so on. That is called overload.","title":"To overload formula:"},{"location":"2017-04-12-SaltStack-Formulas-install/#testing","text":"","title":"Testing"},{"location":"2017-04-12-SaltStack-Formulas-install/#check-if-saltstack-formula-works","text":"1 sudo salt 'host' state.show_sls docker","title":"Check if SaltStack formula works"},{"location":"2017-04-12-SaltStack-Formulas-install/#to-debug-master","text":"1 sudo salt-master -l debug","title":"To debug Master"},{"location":"2017-04-12-SaltStack-Formulas-install/#if-you-get-critical-no-suitable-gitfs-provider-module-is-installed","text":"SaltStack can not find python git backend (pygit2, GitPython or Dulwich). So you need to figure-out this.","title":"If you get: [CRITICAL] No suitable gitfs provider module is installed."},{"location":"2017-04-12-SaltStack-Formulas-install/#look-at-docker-state-module","text":"https://docs.saltstack.com/en/latest/ref/states/all/salt.states.dockerng.html#module-salt.states.dockerng","title":"Look at Docker state module"},{"location":"2017-04-14-How-to-setup-proxy-to-listen-Spotify/","text":"How to create proxy for Spotify \u00b6 Interlude \u00b6 (For fast read, look at Main content ) As you probably already faced, many things not available in different countries. As also Spotify. So you are thinking how to create proxy for yourself, to stream Spotify traffic through it. That mean you are probably a sort of technician. And probably logged in to servers in your life. So you probably used SSH. But SSH is mush more than you think it is. Main content \u00b6 To create a SOCKS5 Proxy server with SSH: ssh [-p remote_port ] -D local_port_to_bind_to [ remote_user @] remote_mashine and that is all. Detailed description \u00b6 -p remote_port - if you have not standard port for SSH; -D local_port_to_bind_to - must be not \"well known\" and not already used port (pick just a random port above ~1024, like 8888 or 9999, up to 32000); remote_mashine - domain name or IP address; SSH is going to create local socket for that port. And going to pipe through SSH tunnel all traffic that arrived at that port to the remote host. So traffic going to go from that host IP to the Internet. So yes, you: need some remote host in the country that has service open. USA is the safe bet. As a tech guy, you can hold a host somewhere already, or ask some friend to pass audio traffic, it is not much. You not even need a root privileges on server to do that. You can do that as a regular user. Client configuration \u00b6 Is very straight-forward. Good luck to you. And happy listening.","title":"How to setup proxy to listen Spotify"},{"location":"2017-04-14-How-to-setup-proxy-to-listen-Spotify/#how-to-create-proxy-for-spotify","text":"","title":"How to create proxy for Spotify"},{"location":"2017-04-14-How-to-setup-proxy-to-listen-Spotify/#interlude","text":"(For fast read, look at Main content ) As you probably already faced, many things not available in different countries. As also Spotify. So you are thinking how to create proxy for yourself, to stream Spotify traffic through it. That mean you are probably a sort of technician. And probably logged in to servers in your life. So you probably used SSH. But SSH is mush more than you think it is.","title":"Interlude"},{"location":"2017-04-14-How-to-setup-proxy-to-listen-Spotify/#main-content","text":"To create a SOCKS5 Proxy server with SSH: ssh [-p remote_port ] -D local_port_to_bind_to [ remote_user @] remote_mashine and that is all.","title":"Main content"},{"location":"2017-04-14-How-to-setup-proxy-to-listen-Spotify/#detailed-description","text":"-p remote_port - if you have not standard port for SSH; -D local_port_to_bind_to - must be not \"well known\" and not already used port (pick just a random port above ~1024, like 8888 or 9999, up to 32000); remote_mashine - domain name or IP address; SSH is going to create local socket for that port. And going to pipe through SSH tunnel all traffic that arrived at that port to the remote host. So traffic going to go from that host IP to the Internet. So yes, you: need some remote host in the country that has service open. USA is the safe bet. As a tech guy, you can hold a host somewhere already, or ask some friend to pass audio traffic, it is not much. You not even need a root privileges on server to do that. You can do that as a regular user.","title":"Detailed description"},{"location":"2017-04-14-How-to-setup-proxy-to-listen-Spotify/#client-configuration","text":"Is very straight-forward. Good luck to you. And happy listening.","title":"Client configuration"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/","text":"Restore deleted LVM (Advanced) \u00b6 Note Case of partition filesystem restore is much-much more trivial. It filesystem got corrupted - refer guides on that topic and use \"TestDisc\" . Intro On the whole Internet until this post was no information on how to restore LVM, when no backup was present. 1. Do backups of the whole drive metadata. 2. On multiple drives - you would do Analyze and Restore for all drives involved. So one way or another. Boot-sector and partition table are deleted from the drive. If only that first sectors was erased, it is great, we can work hard and restore the LVM. If happened the classic in sence of: 1 2 3 dd if = /dev/zero of = /dev/ { h,p,s } d [ a..x ] bs = 512 count = 1 # Do not paste this to root prompt! # Like: # dd if=/dev/zero of=/dev/sda bs=512 count=1 # Do not paste this to root prompt! How to do boot-sectot backups \u00b6 GPT case \u00b6 1 sgdisk -b = /path/to/backup/drive-sgdisk.bak /path/to/device MBR case \u00b6 1 2 3 dd if = /dev/ [ hps ] d [ a-x ] of = /backup/ [ hps ] d [ a-x ] bs = 512 count = 1 # Like: # dd if='/dev/sda of=/backup/'`date --iso`'. sda' bs=512 count=1 LVM \u00b6 LVM complicates the task of recovery, because it is basically a dynamically shifting layer between physical drives partitions and filesystems. Delete the LVM info - filesystem with data basically locked in a chaos claster you can not penetrate. There is small info on Internet on how to resurrect your true HDD/SDD LVM friend(s) alive - but check that info anyway also. Here is the black magic. If you understand LVM in depth. LVM dynamically allocates physical space pieces (Physical extent (PE)). Physical extent (PE) The smallest size in the physical volume that can be assigned to a logical volume (default 4MiB)) This is one of main facts here. Second fact - like most disc solutions - LVM does not shrink by itself. We can do that process, if we want. But LVM, by itself, only expands. Third fact - LVM does not move Physical extents (PE) around, they are statically placed. They allocated from free pool, given to Logical volume (LV), written in it info and that is it. But now you see. LVM is a array of Physical extent (PE), and they was allocated and information stored on them is a complete chaos to us and to tools of recovery (they does not support LVM). That is why it seems impossible to resurrect for most people. But with dedication, way is described here. More info on LVM \u00b6 LVM maps Physical volumes (PV), to Volume groups (VG). Physical volume (PV) Partition on hard disk (or even the disk itself or loopback file) on which you can have volume groups. It has a special header and is divided into physical extents. Think of physical volumes as big building blocks used to build your hard drive. Volume group (VG) Group of physical volumes used as a storage volume (as one disk). They contain logical volumes. Think of volume groups as hard drives. On Volume group (VG) you can describe a Logical volume (LV). Logical volume (LV) A \"virtual/logical partition\" that resides in a volume group and is composed of physical extents. Think of logical volumes as normal partitions. And when Logical volume is going to need to expand its physical space, it does this by getting Physical extent (PE) and mapping it to Logical extent (LE) units, that then LVM includes to Logical volume (LV). It can expand until reaching quota, or free Volume group space available. Logical extent (LE) units are additional abstraction for mapping LVM RAID PEs or PEs from different drives to single Logical volume. Explaining the idea \u00b6 Besides corner stones described in LVM , next piece also plays as important part. Not so known fact, LVM does a backups of it's work information. In /etc/lvm/backup it stores last backup. In /etc/lvm/archive lays a history of previous backup versions. But it is a backup inside the filesystem we trying to restore. Here comes a dirty magic I was talking about. If only we could revive LVM to any metadata state (even non-consistent), than almost certainly we can expect to get the hold of that /etc/lvm/backup . And it going to shine a lite on us. TestDisc can find LVM partition remains, but TestDisc doesn't support work with LVM. It only can say: it looks like some version of LVM table. So TestDisc can't somehow find for us, what version of LVM structure it restores (old or last one), and how consistent that LVM data is. So idea is. To revive the largest LVM TestDisc can find (probably the latest one, because LVM only expands most of the time and LVM PE data is static), and then chroot to that somewhat alive filesystem from working system and restore /etc/lvm/backup . Process of restoring \u00b6 Tip For LVM on multiple drives - you must do Analyze and Restore for all drives involved. After that next step - recovery - is going to be successful. Connect the drive to working system or boot from Live image that is compatible with distribution that you restore. Example As I used Arch Linux on that machine, I used Arch based Antergos Live image. DD-t ISO on a flash drive. Antergos image has X11, Desktop Environment and Gparted prettiness. Install (update) lvm2 and testdisk . LVM2 as you guess provide LVM support. TestDisk is magical but not intuitive tool. Backup full device \u00b6 Backup at least what is on the drive: 1 ddrescue -v -f -n /path/to/drive /backup/path /backup/path/rescue.log Because the process is somewhat nontrivial, long and uses a hack in it. Note ddrescue output can't be archived on the fly . If you need compression - use filesystem level compression on the backup media. Choose right partition table \u00b6 Choose here right type of the partition. It is up to your research. Probably you have one of: [EFI GPT], [Mac ], [Intel ] . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - Hitachi HDS721010CLA330 Please select the partition table type, press Enter when done. [Intel ] Intel/PC partition >[EFI GPT] EFI GPT partition map (Mac i386, some x86_64...) [Humax ] Humax partition table [Mac ] Apple partition map [None ] Non partitioned media [Sun ] Sun Solaris partition [XBox ] XBox partition [Return ] Return to disk selection Hint: Intel partition table type has been detected. Note: Do NOT select 'None' for media with only a single partition. It's very rare for a disk to be 'Non-partitioned'. Analyze of the system (long operation) \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - Hitachi HDS721010CLA330 CHS 121601 255 63 - sector size=512 >[ Analyse ] Analyse current partition structure and search for lost partitions [ Advanced ] Filesystem Utils [ Geometry ] Change disk geometry [ Options ] Modify options [ MBR Code ] Write TestDisk MBR code to first sector [ Delete ] Delete all data in the partition table [ Quit ] Return to disk selection Note Correct disk geometry is required for a successful recovery. 'Analyse' process may give some warnings if it thinks the logical geometry is mismatched. 1 2 3 4 5 6 7 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - CHS 121601 255 63 Partition Start End Size in sectors >P Linux LVM 0 32 33 121601 90 25 1953523712 1 2 3 4 5 6 7 8 9 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - CHS 121601 255 63 Partition Start End Size in sectors 1 P Linux LVM 0 32 33 121601 90 25 1953523712 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - CHS 121601 255 63 Analyse cylinder 553/121600: 00% Linux LVM 0 32 33 121601 80 63 1953523120 Linux 0 65 2 13 0 51 204800 Linux 0 64 63 13 0 49 204800 Linux 0 64 63 13 0 49 204800 Linux 0 64 63 13 0 49 204800 Linux 0 64 63 13 0 49 204800 Linux 0 64 63 13 0 49 204800 Linux 13 0 52 3276 138 62 52428800 Stop Restoring LVM partition with TestDisc \u00b6 After that scan TestDisc review several partitions to restore. One of which is LVM. And it says drive is to small (1T<1.3T or something like that) to reincarnate all that partitions. So you restore the LVM partition (the biggest). Warning At this stage partition and filesystem can be in inconsistent state. Minimize writing to system and proceed further. Restore from backup is going to get us consistent filesystem. Rebooting system \u00b6 To refresh drive boot-partition information - reboot after restoring. Checking state \u00b6 After reboot while doing: 1 2 3 4 5 6 7 8 9 10 11 [antergos@ant-16.9 etc]$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 931.5G 0 disk sda1 8:1 0 931.5G 0 part archvg-boot 254:0 0 100M 0 lvm archvg-archroot 254:1 0 25G 0 lvm /mnt/etc archvg-archvar 254:2 0 15G 0 lvm /run/media/antergos/244907d8-7c9f- archvg-swap 254:3 0 8G 0 lvm archvg-vault 254:4 0 800G 0 lvm archvg-crypt 254:5 0 1G 0 lvm archvg-archhome 254:6 0 20G 0 lvm /run/media/antergos/e2d59443-1e66- You began to see: 1 2 3 [antergos@ant-16.9 etc]$ sudo vgscan Reading volume groups from cache. Found volume group \"archvg\" using metadata type lvm2 Restoring from backup \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 sudo -s # Change volume group attribute to activated vgchange -ay archvg mkdir /mnt/root/ # We need to mount only partition that has backup mount /dev/disk/by-id/archvg-root /mnt/root/ # Locate/print block device attributes blkid /dev/sda1 # /dev/sda1: UUID=\"7SFaGJ-LKnf-mlx7-m8dY-1bg4-epWM-09y8vR\" TYPE=\"LVM2_member\" # Investigate backup. Compare with information above cat /mnt/root/etc/lvm/backup/archvg # Restore volume group configuration vgcfgrestore -f /mnt/root/etc/lvm/backup/archvg archvg #Metadata Restored Next reboot \u00b6 Reboot. After that, if you try to boot to recovered system, - you can get error: 1234F: Because no bootloader was configured. Now we need boot from Live image once more. (optional) Make partition bootable \u00b6 If you was booting from LVM. Mark partition bootable (that flag was in old boot-sector, as you know old-one went away). sudo gparted . Right click on partition. Flags. \"boot\". Mounting everything on working system (preparing for chroot) \u00b6 Now you need by yourself mount all LVM volumes to single tree in /mnt/root, exactly how it was on that system. Because your LVM config is unique, as also mine, I can't give you literal instructions. Example I going to mount: 1 2 3 4 5 6 archvg-archroot /mnt/root/ archvg-boot /mnt/root/boot archvg-archvar /mnt/root/var archvg-archhome /mnt/root/home archvg-vault /mnt/root/mnt/vault archvg-crypt /mnt/root/mnt/crypt So I did: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 sudo -s mkdir -p /mnt/root/ mount /dev/disk/by-id/dm-name-archvg-archroot /mnt/root/ mkdir -p /mnt/root/boot mount /dev/disk/by-id/dm-name-archvg-boot /mnt/root/boot mkdir -p /mnt/root/var mount /dev/disk/by-id/dm-name-archvg-archvar /mnt/root/var mkdir -p /mnt/root/home mount /dev/disk/by-id/dm-name-archvg-archhome /mnt/root/home mkdir -p /mnt/root/mnt/vault mount /dev/disk/by-id/dm-name-archvg-vault /mnt/root/mnt/vault mkdir -p /mnt/root/mnt/crypt mount /dev/disk/by-id/dm-name-archvg-crypt /mnt/root/mnt/crypt swapon /dev/disk/by-id/dm-name-archvg-swap swapon lsblk # check everything Tip Control what you are mounting where with lsblk . You need do everything right before going chroot . Chrooting \u00b6 Chroot to the system: 1 arch-chroot /mnt/root /bin/fish System maps filesystem data to current system. Setup the bootloader \u00b6 On this system bootloader was this : 1 2 3 4 5 6 7 8 9 10 11 pacman -Sy grub lsblk grub-install --target = i386-pc /dev/sda ls /boot/grub/grub.cfg* diff /boot/grub/grub.cfg /boot/grub/grub.cfg.pacnew grub-mkconfig -o /boot/grub/grub.cfg Congratulations! \u00b6 Success After this you have fully restored system. So now you can reboot to your long awaited system and everything is going to run smooth.","title":"Restore of deleted LVM (Advanced)"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#restore-deleted-lvm-advanced","text":"Note Case of partition filesystem restore is much-much more trivial. It filesystem got corrupted - refer guides on that topic and use \"TestDisc\" . Intro On the whole Internet until this post was no information on how to restore LVM, when no backup was present. 1. Do backups of the whole drive metadata. 2. On multiple drives - you would do Analyze and Restore for all drives involved. So one way or another. Boot-sector and partition table are deleted from the drive. If only that first sectors was erased, it is great, we can work hard and restore the LVM. If happened the classic in sence of: 1 2 3 dd if = /dev/zero of = /dev/ { h,p,s } d [ a..x ] bs = 512 count = 1 # Do not paste this to root prompt! # Like: # dd if=/dev/zero of=/dev/sda bs=512 count=1 # Do not paste this to root prompt!","title":"Restore deleted LVM (Advanced)"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#how-to-do-boot-sectot-backups","text":"","title":"How to do boot-sectot backups"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#gpt-case","text":"1 sgdisk -b = /path/to/backup/drive-sgdisk.bak /path/to/device","title":"GPT case"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#mbr-case","text":"1 2 3 dd if = /dev/ [ hps ] d [ a-x ] of = /backup/ [ hps ] d [ a-x ] bs = 512 count = 1 # Like: # dd if='/dev/sda of=/backup/'`date --iso`'. sda' bs=512 count=1","title":"MBR case"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#lvm","text":"LVM complicates the task of recovery, because it is basically a dynamically shifting layer between physical drives partitions and filesystems. Delete the LVM info - filesystem with data basically locked in a chaos claster you can not penetrate. There is small info on Internet on how to resurrect your true HDD/SDD LVM friend(s) alive - but check that info anyway also. Here is the black magic. If you understand LVM in depth. LVM dynamically allocates physical space pieces (Physical extent (PE)). Physical extent (PE) The smallest size in the physical volume that can be assigned to a logical volume (default 4MiB)) This is one of main facts here. Second fact - like most disc solutions - LVM does not shrink by itself. We can do that process, if we want. But LVM, by itself, only expands. Third fact - LVM does not move Physical extents (PE) around, they are statically placed. They allocated from free pool, given to Logical volume (LV), written in it info and that is it. But now you see. LVM is a array of Physical extent (PE), and they was allocated and information stored on them is a complete chaos to us and to tools of recovery (they does not support LVM). That is why it seems impossible to resurrect for most people. But with dedication, way is described here.","title":"LVM"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#more-info-on-lvm","text":"LVM maps Physical volumes (PV), to Volume groups (VG). Physical volume (PV) Partition on hard disk (or even the disk itself or loopback file) on which you can have volume groups. It has a special header and is divided into physical extents. Think of physical volumes as big building blocks used to build your hard drive. Volume group (VG) Group of physical volumes used as a storage volume (as one disk). They contain logical volumes. Think of volume groups as hard drives. On Volume group (VG) you can describe a Logical volume (LV). Logical volume (LV) A \"virtual/logical partition\" that resides in a volume group and is composed of physical extents. Think of logical volumes as normal partitions. And when Logical volume is going to need to expand its physical space, it does this by getting Physical extent (PE) and mapping it to Logical extent (LE) units, that then LVM includes to Logical volume (LV). It can expand until reaching quota, or free Volume group space available. Logical extent (LE) units are additional abstraction for mapping LVM RAID PEs or PEs from different drives to single Logical volume.","title":"More info on LVM"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#explaining-the-idea","text":"Besides corner stones described in LVM , next piece also plays as important part. Not so known fact, LVM does a backups of it's work information. In /etc/lvm/backup it stores last backup. In /etc/lvm/archive lays a history of previous backup versions. But it is a backup inside the filesystem we trying to restore. Here comes a dirty magic I was talking about. If only we could revive LVM to any metadata state (even non-consistent), than almost certainly we can expect to get the hold of that /etc/lvm/backup . And it going to shine a lite on us. TestDisc can find LVM partition remains, but TestDisc doesn't support work with LVM. It only can say: it looks like some version of LVM table. So TestDisc can't somehow find for us, what version of LVM structure it restores (old or last one), and how consistent that LVM data is. So idea is. To revive the largest LVM TestDisc can find (probably the latest one, because LVM only expands most of the time and LVM PE data is static), and then chroot to that somewhat alive filesystem from working system and restore /etc/lvm/backup .","title":"Explaining the idea"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#process-of-restoring","text":"Tip For LVM on multiple drives - you must do Analyze and Restore for all drives involved. After that next step - recovery - is going to be successful. Connect the drive to working system or boot from Live image that is compatible with distribution that you restore. Example As I used Arch Linux on that machine, I used Arch based Antergos Live image. DD-t ISO on a flash drive. Antergos image has X11, Desktop Environment and Gparted prettiness. Install (update) lvm2 and testdisk . LVM2 as you guess provide LVM support. TestDisk is magical but not intuitive tool.","title":"Process of restoring"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#backup-full-device","text":"Backup at least what is on the drive: 1 ddrescue -v -f -n /path/to/drive /backup/path /backup/path/rescue.log Because the process is somewhat nontrivial, long and uses a hack in it. Note ddrescue output can't be archived on the fly . If you need compression - use filesystem level compression on the backup media.","title":"Backup full device"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#choose-right-partition-table","text":"Choose here right type of the partition. It is up to your research. Probably you have one of: [EFI GPT], [Mac ], [Intel ] . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - Hitachi HDS721010CLA330 Please select the partition table type, press Enter when done. [Intel ] Intel/PC partition >[EFI GPT] EFI GPT partition map (Mac i386, some x86_64...) [Humax ] Humax partition table [Mac ] Apple partition map [None ] Non partitioned media [Sun ] Sun Solaris partition [XBox ] XBox partition [Return ] Return to disk selection Hint: Intel partition table type has been detected. Note: Do NOT select 'None' for media with only a single partition. It's very rare for a disk to be 'Non-partitioned'.","title":"Choose right partition table"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#analyze-of-the-system-long-operation","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - Hitachi HDS721010CLA330 CHS 121601 255 63 - sector size=512 >[ Analyse ] Analyse current partition structure and search for lost partitions [ Advanced ] Filesystem Utils [ Geometry ] Change disk geometry [ Options ] Modify options [ MBR Code ] Write TestDisk MBR code to first sector [ Delete ] Delete all data in the partition table [ Quit ] Return to disk selection Note Correct disk geometry is required for a successful recovery. 'Analyse' process may give some warnings if it thinks the logical geometry is mismatched. 1 2 3 4 5 6 7 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - CHS 121601 255 63 Partition Start End Size in sectors >P Linux LVM 0 32 33 121601 90 25 1953523712 1 2 3 4 5 6 7 8 9 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - CHS 121601 255 63 Partition Start End Size in sectors 1 P Linux LVM 0 32 33 121601 90 25 1953523712 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 TestDisk 7.0, Data Recovery Utility, April 2015 Christophe GRENIER <grenier@cgsecurity.org> http://www.cgsecurity.org Disk /dev/sda - 1000 GB / 931 GiB - CHS 121601 255 63 Analyse cylinder 553/121600: 00% Linux LVM 0 32 33 121601 80 63 1953523120 Linux 0 65 2 13 0 51 204800 Linux 0 64 63 13 0 49 204800 Linux 0 64 63 13 0 49 204800 Linux 0 64 63 13 0 49 204800 Linux 0 64 63 13 0 49 204800 Linux 0 64 63 13 0 49 204800 Linux 13 0 52 3276 138 62 52428800 Stop","title":"Analyze of the system (long operation)"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#restoring-lvm-partition-with-testdisc","text":"After that scan TestDisc review several partitions to restore. One of which is LVM. And it says drive is to small (1T<1.3T or something like that) to reincarnate all that partitions. So you restore the LVM partition (the biggest). Warning At this stage partition and filesystem can be in inconsistent state. Minimize writing to system and proceed further. Restore from backup is going to get us consistent filesystem.","title":"Restoring LVM partition with TestDisc"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#rebooting-system","text":"To refresh drive boot-partition information - reboot after restoring.","title":"Rebooting system"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#checking-state","text":"After reboot while doing: 1 2 3 4 5 6 7 8 9 10 11 [antergos@ant-16.9 etc]$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 931.5G 0 disk sda1 8:1 0 931.5G 0 part archvg-boot 254:0 0 100M 0 lvm archvg-archroot 254:1 0 25G 0 lvm /mnt/etc archvg-archvar 254:2 0 15G 0 lvm /run/media/antergos/244907d8-7c9f- archvg-swap 254:3 0 8G 0 lvm archvg-vault 254:4 0 800G 0 lvm archvg-crypt 254:5 0 1G 0 lvm archvg-archhome 254:6 0 20G 0 lvm /run/media/antergos/e2d59443-1e66- You began to see: 1 2 3 [antergos@ant-16.9 etc]$ sudo vgscan Reading volume groups from cache. Found volume group \"archvg\" using metadata type lvm2","title":"Checking state"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#restoring-from-backup","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 sudo -s # Change volume group attribute to activated vgchange -ay archvg mkdir /mnt/root/ # We need to mount only partition that has backup mount /dev/disk/by-id/archvg-root /mnt/root/ # Locate/print block device attributes blkid /dev/sda1 # /dev/sda1: UUID=\"7SFaGJ-LKnf-mlx7-m8dY-1bg4-epWM-09y8vR\" TYPE=\"LVM2_member\" # Investigate backup. Compare with information above cat /mnt/root/etc/lvm/backup/archvg # Restore volume group configuration vgcfgrestore -f /mnt/root/etc/lvm/backup/archvg archvg #Metadata Restored","title":"Restoring from backup"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#next-reboot","text":"Reboot. After that, if you try to boot to recovered system, - you can get error: 1234F: Because no bootloader was configured. Now we need boot from Live image once more.","title":"Next reboot"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#optional-make-partition-bootable","text":"If you was booting from LVM. Mark partition bootable (that flag was in old boot-sector, as you know old-one went away). sudo gparted . Right click on partition. Flags. \"boot\".","title":"(optional) Make partition bootable"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#mounting-everything-on-working-system-preparing-for-chroot","text":"Now you need by yourself mount all LVM volumes to single tree in /mnt/root, exactly how it was on that system. Because your LVM config is unique, as also mine, I can't give you literal instructions. Example I going to mount: 1 2 3 4 5 6 archvg-archroot /mnt/root/ archvg-boot /mnt/root/boot archvg-archvar /mnt/root/var archvg-archhome /mnt/root/home archvg-vault /mnt/root/mnt/vault archvg-crypt /mnt/root/mnt/crypt So I did: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 sudo -s mkdir -p /mnt/root/ mount /dev/disk/by-id/dm-name-archvg-archroot /mnt/root/ mkdir -p /mnt/root/boot mount /dev/disk/by-id/dm-name-archvg-boot /mnt/root/boot mkdir -p /mnt/root/var mount /dev/disk/by-id/dm-name-archvg-archvar /mnt/root/var mkdir -p /mnt/root/home mount /dev/disk/by-id/dm-name-archvg-archhome /mnt/root/home mkdir -p /mnt/root/mnt/vault mount /dev/disk/by-id/dm-name-archvg-vault /mnt/root/mnt/vault mkdir -p /mnt/root/mnt/crypt mount /dev/disk/by-id/dm-name-archvg-crypt /mnt/root/mnt/crypt swapon /dev/disk/by-id/dm-name-archvg-swap swapon lsblk # check everything Tip Control what you are mounting where with lsblk . You need do everything right before going chroot .","title":"Mounting everything on working system (preparing for chroot)"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#chrooting","text":"Chroot to the system: 1 arch-chroot /mnt/root /bin/fish System maps filesystem data to current system.","title":"Chrooting"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#setup-the-bootloader","text":"On this system bootloader was this : 1 2 3 4 5 6 7 8 9 10 11 pacman -Sy grub lsblk grub-install --target = i386-pc /dev/sda ls /boot/grub/grub.cfg* diff /boot/grub/grub.cfg /boot/grub/grub.cfg.pacnew grub-mkconfig -o /boot/grub/grub.cfg","title":"Setup the bootloader"},{"location":"2017-05-04-Restore-of-deleted-LVM-(Advanced)/#congratulations","text":"Success After this you have fully restored system. So now you can reboot to your long awaited system and everything is going to run smooth.","title":"Congratulations!"},{"location":"about/","text":"About \u00b6 This is Anton Latukha personal website. IT specialist that devoted his life to computer stuff. Best skill in Linux systems and building any size of infrastructures on them. Architect, business minded, DevOps. Telecommunication postgraduate.","title":"About"},{"location":"about/#about","text":"This is Anton Latukha personal website. IT specialist that devoted his life to computer stuff. Best skill in Linux systems and building any size of infrastructures on them. Architect, business minded, DevOps. Telecommunication postgraduate.","title":"About"},{"location":"bio/","text":"GitHub | Old GitHub | Twitter | LinkedIn | CV Biography \u00b6 I am a man pretty versatile in IT sphere. My main goal is to bring good products in Haskell. It synergizes with my current skills. I would appreciate errands and being responsible for backend logic, especially regarding DevOps services. I love solving efficiently \u2013 creating a valuable product of powers (opportunities) given by the world (provided by IT, Open Source, Cloud) and my glue. Mostly, if business has a request \u2013 someone already solved or partially solved it in the world and solution is mostly available or described on the global network. The only unique business code is a glue code or unique code for the core products. To shape myself I always take the most rigorous way, to be of the best quality. To be able to fully go into work, focused, move fast, make better quality, productive in the mode of solving into the result. Currently I prepared the most solid ground of skills and knowledge you would meet in someone that knows the basics of Haskell. I am serious about full understanding of the base and Category theory and aligned to Haskell mathematics and terminology \u2013 since they multiply the power the more you learned to think in the right way. Theory comes-out into real world of practice after deep understanding of the base of Category theory is finished (when category, functor and natural transformation understood) and structures bring the fruits. Over life it seems to go so I would be an architect, at least I want to move in Haskell in that direction. The person, who understands the field of technology and on the right page with different people, entrepreneurs and businessmen, managers, programmers, admins, DB-admins, web-developers, hardware engineers. During freelance I got experience working with businessmen. I discuss with them the view, priorities, and give 2-3 variants to get valuable input, get the real target better. Then with that understanding I make solution that even better suits their vision. Most times my implementations take less time, and have less cost. I work and give back as good as I only can. I love simple, robust, maintainable solutions suited for the future and grows of the business. In IT using right approach in several dimensions (technical, management, psychological, social) it is possible to create very valuable solutions. I have great telecommunication education, graduate and postgraduate, having a lot of math and physics. On the side, had Cisco CCNA, even taught it also for paid. Skills \u00b6 Main skills \u00b6 Solid foundations of Haskell: https://github.com/Anton-Latukha/Haskell-Programming-From-First-Principles, https://github.com/Anton-Latukha/haskell-notes. Solid Category theory foundations, & related to Haskell, Lambda calculus & Computer science mathematical theories. DevOps skills: knowledge/experience of many Opens Source projects, containerization (& creating custom container images and custom IT systems from them), clustering (Kubernetes clusters), CI (Jenkins, Travis, Hydra CI, GitLab CI), AWS and GCE services and the minimization of their costs, Terraform & Ansible. Nix language & Nix tooling & NixPkgs & NixOps & Hydra. Had a small team in command. Deployed Hydra CI, managed NixOS servers thru NixOps, written custom Nix language code. Contributed to upstream NixPkgs. I maintain a couple of packages in NixPkgs. Written the new Nix installer (dod a NixCon talk, to restate and merge it https://youtu.be/hhgrCV_r7YE?t=6364), core Nix team still not merged it (https://github.com/NixOS/nix/pull/1565). Went on and gradually participating in HNix. Creative at work, knowledge of many technologies, hints, ability to write in many programming languages and combine them with any services. Strict dictionary of terms and semantics, ability to reason abstractly & flexibly. Knowledgeable in many mathematical areas. Deep understanding of topics which I work in. Good ability to talk and understand with managers & specialists. Having a strong character, rigorous at duties (moral character), can lead and manage people. OS Linux \u00b6 NixOS Debian Ubuntu (from 7.04 to today) CentOS Fedora (My first Linux was Red Hat Linux 8) Arch Linux Alpine Linux deep knowledge of POSIX standard can efficiently create&work efficiently in any Linux environment. For myself I use Arch Linux, that enables me real great knowledge and understanding of depth and all bleeding edge technologies. Have some experience in more exotic OS \u00b6 IBM AIX systems. 6.1 and 7.1. I got IBM internship, but sadly couldn't be accepted by IBM because University document reasons (finished my degree). IBM staff, like a great company do, in apology gave me 3 basic courses of IBM AIX systems. FreeBSD Red Hat OS Windows \u00b6 Starting from MS DOS 3.0, MS DOS 5.0, Windows 1.0, 3.11, 95, 95 OSR2, 98, 98 SP1, SP2, Windows NT, Windows 2000, Windows 2003 Server, Windows 2008 Server, Windows 2012 Server. In childhood I had only old PCs, and was or PC circle. I was main administrator of system integration company SI BIS, infrastructure was on Microsoft products, this is where my point of Windows 2008 Server, Windows 2012 Server from. Non-exhaustive list of technologies I have experience in \u00b6 Init subsystems \u00b6 Systemd SysV Upstart Configuration/Code Management \u00b6 Git Terraform Ansible Nix language & NixOps SaltStack Puppet Virtualization & containerization \u00b6 Virtualization and containerization theory & practice Kubernetes Docker (Compose, Machine. Swarm, private repositories) Cloud platforms: AWS EC2, ECS; GC GCE, GKE KVM VMWare solutions line with ESXi (5.0-5.2) OpenVZ HyperV LXC Databases \u00b6 Database theory. Structure, keys, normalization, queries, transactions, users, rights, boolean algebra. SQL language MySQL MariaDB PostgresSQL InfluxDB (special DB for time-series data) MongoDB Cassandra Microsoft SQL Microsoft Access Briefly touched NoSQL, MLP databases. Couchbase and MongoDB. Monitoring \u00b6 Zabbix (and it's theory of items, triggers, etc., low level scanning) Grafana InfluxDB netdata sources Graphite SNMP for Linux systems & networking equipment Windows SNMP provider Windows WMI Windows Perf Microsoft PowerShell Windows sysinfo Windows logging and troubleshoot experience Linux Filesystem Hierarchy Linux logging (Syslog, journald and its feeatures) Linux Finger S.M.A.R.T. (SmartMonTools) Hardware sensors information (lm_sensors and such) Zabbix active agents Backup solutions \u00b6 Bacula BareOS Rsync Backup to Cloud storage via WebDAV or CLI Cloud snapshotting, backups, Glasier Filesystem snapshotting, RAID replication Filesystem \u00b6 ZFS Btrfs Programming & scripting languages experience \u00b6 Haskell (in depth) Bash, Bourne Shell, Dash, Fish, ZSH, Bat files (also in POSIX standard, ShellFire framework) Python (basics) Go Node.JS (+ Jade, Express.JS) JavaScript (+ jQuerry, CSS, HTML5) C C++ (basics) QT, QML, QTQuick Assembler (TASM) BASIC (ZX Spectrum, my first PC) Visual Basic Pascal Lisp C#, .Net VoIP \u00b6 Asterisk Network education help me a lot here also CI/CD \u00b6 Solid foundations & writing of Haskell property testing. Knowledge of Category theory and related math fields help in property testing. Jenkins - have basic experience with deploying and using Jenkins building pipelines and applying unit tests. Travis - even written an article about Travis that later was readopted in Summoner project. Hydra \u2013 as already was said deployed and maintained Hydra CI setup in a project. Network OS \u00b6 Cisco IOS 12.4T, and 15M Cisco Catalyst MikroTik RouterBOARD Had brief experience with Huawei VRP to understand how much it is rewritten IOS (but all names are changed). Some technologies also. Knowledge of telecommunications \u00b6 Have a higher degree at Telecommunications. Master and underway Postgraduate degree. Bachelor degree was more software centered (STP modification for PON networks). Master degree more hardware centered (WDM in PON networks). From my interest to hard subject solidly I know software, hardware, and underlying Telecommunication theory, Calculus, Probability theory, Classical electrodynamics that was strong points at my University. I get official CCNA education. And love Cisco tech and console. With a team created networking lab at university. With complex infrastructure. Sometime after that, my scientific director got a contract to conduct courses. I wrote part of the materials, and was main practical knowledge lecturer and held practices for business courses. Courses was created specifically for the Ukrainian national broadcasting company and consisted of questions they wanted. From basics of networking, ISO levels 1-3, IP/TCP stack, Cisco and MikroTik basics, basics of switching, VLANs, basic routing & protocols, to basics of encryption, and VPN tunneling, client and site-to-site. This all I explained them in detail. And there were 6 waves of courses. That is why I have knowledge of networks on something more than Cisco CCNA level because of my Networking education & CCNA courses & some job and science experience of additional and essential topics like multi-area OSPF, MPLS, optical networks. Contributions \u00b6 Big part of my contributions can be seen at GitHub: https://github.com/pulls?q=is%3Apr+author%3AAnton-Latukha NixPkgs: https://github.com/NixOS/nixpkgs/pulls?utf8=%E2%9C%93&q=is%3Apr+author%3AAnton-Latukha+ HaskellWiki: https://wiki.haskell.org/Special:Contributions/Anton-Latukha HNix: https://github.com/haskell-nix/hnix/pulls?utf8=%E2%9C%93&q=is%3Apr+author%3AAnton-Latukha+ ArchWiki: - one of the best Linux information resources ( old account and current account ). Spacemacs: https://github.com/syl20bnr/spacemacs/pulls?q=is%3Apr+is%3Aclosed+author%3AAnton-Latukha OpenStreetMap: profile . Also contributed to many other projects: KDE community, Mozilla Corporation, SaltStack, etc.","title":"Biography"},{"location":"bio/#biography","text":"I am a man pretty versatile in IT sphere. My main goal is to bring good products in Haskell. It synergizes with my current skills. I would appreciate errands and being responsible for backend logic, especially regarding DevOps services. I love solving efficiently \u2013 creating a valuable product of powers (opportunities) given by the world (provided by IT, Open Source, Cloud) and my glue. Mostly, if business has a request \u2013 someone already solved or partially solved it in the world and solution is mostly available or described on the global network. The only unique business code is a glue code or unique code for the core products. To shape myself I always take the most rigorous way, to be of the best quality. To be able to fully go into work, focused, move fast, make better quality, productive in the mode of solving into the result. Currently I prepared the most solid ground of skills and knowledge you would meet in someone that knows the basics of Haskell. I am serious about full understanding of the base and Category theory and aligned to Haskell mathematics and terminology \u2013 since they multiply the power the more you learned to think in the right way. Theory comes-out into real world of practice after deep understanding of the base of Category theory is finished (when category, functor and natural transformation understood) and structures bring the fruits. Over life it seems to go so I would be an architect, at least I want to move in Haskell in that direction. The person, who understands the field of technology and on the right page with different people, entrepreneurs and businessmen, managers, programmers, admins, DB-admins, web-developers, hardware engineers. During freelance I got experience working with businessmen. I discuss with them the view, priorities, and give 2-3 variants to get valuable input, get the real target better. Then with that understanding I make solution that even better suits their vision. Most times my implementations take less time, and have less cost. I work and give back as good as I only can. I love simple, robust, maintainable solutions suited for the future and grows of the business. In IT using right approach in several dimensions (technical, management, psychological, social) it is possible to create very valuable solutions. I have great telecommunication education, graduate and postgraduate, having a lot of math and physics. On the side, had Cisco CCNA, even taught it also for paid.","title":"Biography"},{"location":"bio/#skills","text":"","title":"Skills"},{"location":"bio/#main-skills","text":"Solid foundations of Haskell: https://github.com/Anton-Latukha/Haskell-Programming-From-First-Principles, https://github.com/Anton-Latukha/haskell-notes. Solid Category theory foundations, & related to Haskell, Lambda calculus & Computer science mathematical theories. DevOps skills: knowledge/experience of many Opens Source projects, containerization (& creating custom container images and custom IT systems from them), clustering (Kubernetes clusters), CI (Jenkins, Travis, Hydra CI, GitLab CI), AWS and GCE services and the minimization of their costs, Terraform & Ansible. Nix language & Nix tooling & NixPkgs & NixOps & Hydra. Had a small team in command. Deployed Hydra CI, managed NixOS servers thru NixOps, written custom Nix language code. Contributed to upstream NixPkgs. I maintain a couple of packages in NixPkgs. Written the new Nix installer (dod a NixCon talk, to restate and merge it https://youtu.be/hhgrCV_r7YE?t=6364), core Nix team still not merged it (https://github.com/NixOS/nix/pull/1565). Went on and gradually participating in HNix. Creative at work, knowledge of many technologies, hints, ability to write in many programming languages and combine them with any services. Strict dictionary of terms and semantics, ability to reason abstractly & flexibly. Knowledgeable in many mathematical areas. Deep understanding of topics which I work in. Good ability to talk and understand with managers & specialists. Having a strong character, rigorous at duties (moral character), can lead and manage people.","title":"Main skills"},{"location":"bio/#os-linux","text":"NixOS Debian Ubuntu (from 7.04 to today) CentOS Fedora (My first Linux was Red Hat Linux 8) Arch Linux Alpine Linux deep knowledge of POSIX standard can efficiently create&work efficiently in any Linux environment. For myself I use Arch Linux, that enables me real great knowledge and understanding of depth and all bleeding edge technologies.","title":"OS Linux"},{"location":"bio/#have-some-experience-in-more-exotic-os","text":"IBM AIX systems. 6.1 and 7.1. I got IBM internship, but sadly couldn't be accepted by IBM because University document reasons (finished my degree). IBM staff, like a great company do, in apology gave me 3 basic courses of IBM AIX systems. FreeBSD Red Hat","title":"Have some experience in more exotic OS"},{"location":"bio/#os-windows","text":"Starting from MS DOS 3.0, MS DOS 5.0, Windows 1.0, 3.11, 95, 95 OSR2, 98, 98 SP1, SP2, Windows NT, Windows 2000, Windows 2003 Server, Windows 2008 Server, Windows 2012 Server. In childhood I had only old PCs, and was or PC circle. I was main administrator of system integration company SI BIS, infrastructure was on Microsoft products, this is where my point of Windows 2008 Server, Windows 2012 Server from.","title":"OS Windows"},{"location":"bio/#non-exhaustive-list-of-technologies-i-have-experience-in","text":"","title":"Non-exhaustive list of technologies I have experience in"},{"location":"bio/#init-subsystems","text":"Systemd SysV Upstart","title":"Init subsystems"},{"location":"bio/#configurationcode-management","text":"Git Terraform Ansible Nix language & NixOps SaltStack Puppet","title":"Configuration/Code Management"},{"location":"bio/#virtualization-containerization","text":"Virtualization and containerization theory & practice Kubernetes Docker (Compose, Machine. Swarm, private repositories) Cloud platforms: AWS EC2, ECS; GC GCE, GKE KVM VMWare solutions line with ESXi (5.0-5.2) OpenVZ HyperV LXC","title":"Virtualization &amp; containerization"},{"location":"bio/#databases","text":"Database theory. Structure, keys, normalization, queries, transactions, users, rights, boolean algebra. SQL language MySQL MariaDB PostgresSQL InfluxDB (special DB for time-series data) MongoDB Cassandra Microsoft SQL Microsoft Access Briefly touched NoSQL, MLP databases. Couchbase and MongoDB.","title":"Databases"},{"location":"bio/#monitoring","text":"Zabbix (and it's theory of items, triggers, etc., low level scanning) Grafana InfluxDB netdata sources Graphite SNMP for Linux systems & networking equipment Windows SNMP provider Windows WMI Windows Perf Microsoft PowerShell Windows sysinfo Windows logging and troubleshoot experience Linux Filesystem Hierarchy Linux logging (Syslog, journald and its feeatures) Linux Finger S.M.A.R.T. (SmartMonTools) Hardware sensors information (lm_sensors and such) Zabbix active agents","title":"Monitoring"},{"location":"bio/#backup-solutions","text":"Bacula BareOS Rsync Backup to Cloud storage via WebDAV or CLI Cloud snapshotting, backups, Glasier Filesystem snapshotting, RAID replication","title":"Backup solutions"},{"location":"bio/#filesystem","text":"ZFS Btrfs","title":"Filesystem"},{"location":"bio/#programming-scripting-languages-experience","text":"Haskell (in depth) Bash, Bourne Shell, Dash, Fish, ZSH, Bat files (also in POSIX standard, ShellFire framework) Python (basics) Go Node.JS (+ Jade, Express.JS) JavaScript (+ jQuerry, CSS, HTML5) C C++ (basics) QT, QML, QTQuick Assembler (TASM) BASIC (ZX Spectrum, my first PC) Visual Basic Pascal Lisp C#, .Net","title":"Programming &amp; scripting languages experience"},{"location":"bio/#voip","text":"Asterisk Network education help me a lot here also","title":"VoIP"},{"location":"bio/#cicd","text":"Solid foundations & writing of Haskell property testing. Knowledge of Category theory and related math fields help in property testing. Jenkins - have basic experience with deploying and using Jenkins building pipelines and applying unit tests. Travis - even written an article about Travis that later was readopted in Summoner project. Hydra \u2013 as already was said deployed and maintained Hydra CI setup in a project.","title":"CI/CD"},{"location":"bio/#network-os","text":"Cisco IOS 12.4T, and 15M Cisco Catalyst MikroTik RouterBOARD Had brief experience with Huawei VRP to understand how much it is rewritten IOS (but all names are changed). Some technologies also.","title":"Network OS"},{"location":"bio/#knowledge-of-telecommunications","text":"Have a higher degree at Telecommunications. Master and underway Postgraduate degree. Bachelor degree was more software centered (STP modification for PON networks). Master degree more hardware centered (WDM in PON networks). From my interest to hard subject solidly I know software, hardware, and underlying Telecommunication theory, Calculus, Probability theory, Classical electrodynamics that was strong points at my University. I get official CCNA education. And love Cisco tech and console. With a team created networking lab at university. With complex infrastructure. Sometime after that, my scientific director got a contract to conduct courses. I wrote part of the materials, and was main practical knowledge lecturer and held practices for business courses. Courses was created specifically for the Ukrainian national broadcasting company and consisted of questions they wanted. From basics of networking, ISO levels 1-3, IP/TCP stack, Cisco and MikroTik basics, basics of switching, VLANs, basic routing & protocols, to basics of encryption, and VPN tunneling, client and site-to-site. This all I explained them in detail. And there were 6 waves of courses. That is why I have knowledge of networks on something more than Cisco CCNA level because of my Networking education & CCNA courses & some job and science experience of additional and essential topics like multi-area OSPF, MPLS, optical networks.","title":"Knowledge of telecommunications"},{"location":"bio/#contributions","text":"Big part of my contributions can be seen at GitHub: https://github.com/pulls?q=is%3Apr+author%3AAnton-Latukha NixPkgs: https://github.com/NixOS/nixpkgs/pulls?utf8=%E2%9C%93&q=is%3Apr+author%3AAnton-Latukha+ HaskellWiki: https://wiki.haskell.org/Special:Contributions/Anton-Latukha HNix: https://github.com/haskell-nix/hnix/pulls?utf8=%E2%9C%93&q=is%3Apr+author%3AAnton-Latukha+ ArchWiki: - one of the best Linux information resources ( old account and current account ). Spacemacs: https://github.com/syl20bnr/spacemacs/pulls?q=is%3Apr+is%3Aclosed+author%3AAnton-Latukha OpenStreetMap: profile . Also contributed to many other projects: KDE community, Mozilla Corporation, SaltStack, etc.","title":"Contributions"}]}